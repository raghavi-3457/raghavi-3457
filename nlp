#morphology
add_delete_table={
    "s": "",
    "es": "",
    "ed": "",
    "ing" : "",
}
def stem_word(word):
    for suffix,replacement in add_delete_table.items():
        if word.endswith(suffix):
            return word[:-len(suffix)] + replacement
    return word

words=["jumps","jumping","played","playing"]

stemmed_words = [stem_word(word) for word in words]

for word, stemmed in zip(words,stemmed_words):
    print(f"{word} -> {stemmed}")

#vertibi decoding
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize,sent_tokenize
stop_words=set(stopwords.words("english"))
text="Sukanya, Raj and Neha are my good friends"\
"Sukanya is getting married next year"\
"Marraige is a big step in one's life"\
"It is both exciting and frightening"\
"But friendship is a sacred bonf between people"\
"It is a special kind of clone between us"\
"Many of you must have tried seaching for a friend"\
"But never found the right one"

tokenized=sent_tokenize(text)
for i in tokenized:
    wordsList=nltk.word_tokenize(i)
    wordsList=[w for w in wordsList if not w in stop_words]
    tagged=nltk.pos_tag(wordsList)
print(tagged)

#class based
from collections import defaultdict
import re

class NgramModel:
    def __init__(self, n):
        self.n = n
        self.ngrams = defaultdict(int)
        self.total_count = 0

    def train(self, text):
        words = re.findall(r'\w+', text.lower())
        for i in range(len(words) - self.n + 1):
            ngram = tuple(words[i:i + self.n])
            self.ngrams[ngram] += 1
            self.total_count += 1

    def prob(self, ngram):
        return self.ngrams[ngram] / self.total_count if self.total_count > 0 else 0

text = "this is a sample example for a class based ngram"
n = 2
model = NgramModel(n)
model.train(text)
class_based = ('class', 'based')
simple_example = ('sample', 'example')

print("Probability of ('class', 'based'):", model.prob(class_based))
print("Probability of ('sample', 'example'):", model.prob(simple_example))


# dependency parsing
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')


sent = "one cat chased a mouse in the garden"

tokens = nltk.word_tokenize(sent)


tagged = nltk.pos_tag(tokens)

pattern = 'NP: {<DT>?<NN>*<NN>}'


chunk_parser = nltk.RegexpParser(pattern)


chunk_sentence = chunk_parser.parse(tagged)


print(chunk_sentence)

chunk_sentence.draw()
